
\documentclass[
	fontsize=11pt, % Base font size
	twoside=false, % Use different layouts for even and odd pages (in particular, if twoside=true, the margin column will be always on the outside)
	%open=any, % If twoside=true, uncomment this to force new chapters to start on any page, not only on right (odd) pages
	%chapterprefix=true, % Uncomment to use the word "Chapter" before chapter numbers everywhere they appear
	%chapterentrydots=true, % Uncomment to output dots from the chapter name to the page number in the table of contents
	numbers=noenddot, % Comment to output dots after chapter numbers; the most common values for this option are: enddot, noenddot and auto (see the KOMAScript documentation for an in-depth explanation)
	%draft=true, % If uncommented, rulers will be added in the header and footer
	%overfullrule=true, % If uncommented, overly long lines will be marked by a black box; useful for correcting spacing problems
]{kaobook}

% Set the language
\usepackage[english]{babel} % Load characters and hyphenation
\usepackage[english=british]{csquotes} % English quotes

\usepackage{bm}


% txfonts/pxfonts

% Load packages for testing
\usepackage{blindtext}
%\usepackage{showframe} % Uncomment to show boxes around the text area, margin, header and footer
%\usepackage{showlabels} % Uncomment to output the content of \label commands to the document where they are used

% Load the bibliography package
\usepackage{styles/kaobiblio}
\addbibresource{biblio.bib} % Bibliography file

% Load mathematical packages for theorems and related environments. NOTE: choose only one between 'mdftheorems' and 'plaintheorems'.
\usepackage{styles/mdftheorems}
%\usepackage{styles/plaintheorems}


\graphicspath{{images/}} % Paths in which to look for images

% \RequirePackage{times}

\DeclareMathOperator{\cA}{{\mathcal A}}
\DeclareMathOperator{\cB}{{\mathcal B}}
\DeclareMathOperator{\cC}{{\mathcal C}}
\DeclareMathOperator{\cD}{{\mathcal D}}
\DeclareMathOperator{\cE}{{\mathcal E}}
\DeclareMathOperator{\cF}{{\mathcal F}}
\DeclareMathOperator{\cG}{{\mathcal G}}
\DeclareMathOperator{\cM}{{\mathcal M}}
\DeclareMathOperator{\cN}{{\mathcal N}}
\DeclareMathOperator{\cP}{{\mathcal P}}
\DeclareMathOperator{\cX}{{\mathcal X}}
\DeclareMathOperator{\cY}{{\mathcal Y}}
\DeclareMathOperator{\cZ}{{\mathcal Z}}

\DeclareMathOperator{\bA}{{\boldsymbol A}}
\DeclareMathOperator{\bB}{{\boldsymbol B}}
\DeclareMathOperator{\bC}{{\boldsymbol C}}
\DeclareMathOperator{\bD}{{\boldsymbol D}}
\DeclareMathOperator{\bE}{{\boldsymbol E}}
\DeclareMathOperator{\bF}{{\boldsymbol F}}
\DeclareMathOperator{\bG}{{\boldsymbol G}}
\DeclareMathOperator{\bH}{{\boldsymbol H}}
\DeclareMathOperator{\bI}{{\boldsymbol I}}
\DeclareMathOperator{\bJ}{{\boldsymbol J}}
\DeclareMathOperator{\bK}{{\boldsymbol K}}
\DeclareMathOperator{\bL}{{\boldsymbol L}}
\DeclareMathOperator{\bM}{{\boldsymbol M}}
\DeclareMathOperator{\bN}{{\boldsymbol N}}
\DeclareMathOperator{\bO}{{\boldsymbol O}}
\DeclareMathOperator{\bP}{{\boldsymbol P}}
\DeclareMathOperator{\bQ}{{\boldsymbol Q}}
\DeclareMathOperator{\bR}{{\boldsymbol R}}
\DeclareMathOperator{\bS}{{\boldsymbol S}}
\DeclareMathOperator{\bT}{{\boldsymbol T}}
\DeclareMathOperator{\bU}{{\boldsymbol U}}
\DeclareMathOperator{\bV}{{\boldsymbol V}}
\DeclareMathOperator{\bW}{{\boldsymbol W}}
\DeclareMathOperator{\bX}{{\boldsymbol X}}
\DeclareMathOperator{\bY}{{\boldsymbol Y}}
\DeclareMathOperator{\bZ}{{\boldsymbol Z}}

\DeclareMathOperator{\ba}{{\boldsymbol a}}
\DeclareMathOperator{\bb}{{\boldsymbol b}}
\DeclareMathOperator{\bc}{{\boldsymbol c}}
\DeclareMathOperator{\bd}{{\boldsymbol d}}
\DeclareMathOperator{\be}{{\boldsymbol e}}
% \DeclareMathOperator{\bf}{{\boldsymbol f}}
\DeclareMathOperator{\bg}{{\boldsymbol g}}
\DeclareMathOperator{\bh}{{\boldsymbol h}}
\DeclareMathOperator{\bi}{{\boldsymbol i}}
\DeclareMathOperator{\bj}{{\boldsymbol j}}
\DeclareMathOperator{\bk}{{\boldsymbol k}}
\DeclareMathOperator{\bl}{{\boldsymbol l}}
% \DeclareMathOperator{\bm}{{\boldsymbol m}}
\DeclareMathOperator{\bn}{{\boldsymbol n}}
\DeclareMathOperator{\bo}{{\boldsymbol o}}
\DeclareMathOperator{\bp}{{\boldsymbol p}}
\DeclareMathOperator{\bq}{{\boldsymbol q}}
\DeclareMathOperator{\br}{{\boldsymbol r}}
\DeclareMathOperator{\bs}{{\boldsymbol s}}
\DeclareMathOperator{\bt}{{\boldsymbol t}}
\DeclareMathOperator{\bu}{{\boldsymbol u}}
\DeclareMathOperator{\bv}{{\boldsymbol v}}
\DeclareMathOperator{\bw}{{\boldsymbol w}}
\DeclareMathOperator{\bx}{{\boldsymbol x}}
\DeclareMathOperator{\by}{{\boldsymbol y}}
\DeclareMathOperator{\bz}{{\boldsymbol z}}

\DeclareMathOperator{\bLambda}{{\boldsymbol \Lambda}}

\DeclareMathOperator{\bone}{\boldsymbol 1}

\DeclareMathOperator{\beps}{\boldsymbol \varepsilon}
\DeclareMathOperator{\bSigma}{\boldsymbol \Sigma}

\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\mode}{mode}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\med}{med}
\DeclareMathOperator{\pen}{pen}
\DeclareMathOperator{\inte}{int}
\DeclareMathOperator{\dom}{dom}


\DeclareMathOperator{\ber}{Bernoulli}
\DeclareMathOperator{\bet}{Beta}
\DeclareMathOperator{\bin}{Binomial}
\DeclareMathOperator{\chisq}{ChiSq}
\DeclareMathOperator{\expo}{Exponential}
\DeclareMathOperator{\fis}{Fisher}
\DeclareMathOperator{\gam}{Gamma}
\DeclareMathOperator{\mul}{Multinomial}
\DeclareMathOperator{\nor}{Normal}
\DeclareMathOperator{\stu}{Student}
\DeclareMathOperator{\uni}{Uniform}

\DeclareMathOperator{\new}{new}



\DeclareMathOperator{\sigmoid}{sigmoid}
\DeclareMathOperator{\leb}{Lebesgue}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}

\DeclareMathOperator*{\spa}{span}
\DeclareMathOperator{\proj}{proj}
\DeclareMathOperator{\cov}{cov}

\newcommand{\eps}{\varepsilon}

\renewcommand{\P}{\mathbb P}
\newcommand{\E}{\mathbb E}
\newcommand{\R}{\mathbb R}
\newcommand{\N}{\mathbb N}
\newcommand{\var}{\mathbb V}

\newcommand{\wh}{\widehat}
\newcommand{\wt}{\widetilde}

\newcommand{\ind}[1]{\mathbf 1_{#1}}
\newcommand{\grad}{\nabla}


\newcommand{\mgeq}{\succcurlyeq}
\newcommand{\mleq}{\preccurlyeq}
\newcommand{\goes}{\rightarrow}
\newcommand{\go}{\rightarrow}

\newcommand{\norm}[1]{\| #1 \|}
\newcommand{\inr}[1]{\langle #1 \rangle}

\newcommand{\gopro}{\overset{\P}{\rightarrow}}
\newcommand{\goas}{\overset{\text{as\ }}{\rightarrow}}
\newcommand{\goqr}{\overset{\text{$L^2$\ }}{\rightarrow}}
\newcommand{\gosto}{\leadsto}


% \newcommand{\lest}{ \underset{\text{st}}{\leq}}
\newcommand{\lest}{\preceq}
% \newcommand{\gest}{\underset{\text{st}}{\qeq}}
\newcommand{\gest}{\succeq}



% \makeindex[columns=3, title=Alphabetical Index, intoc] % Make LaTeX produce the files required to compile the index

% \makeglossaries % Make LaTeX produce the files required to compile the glossary

% \makenomenclature % Make LaTeX produce the files required to compile the nomenclature

% Reset sidenote counter at chapters
%\counterwithin*{sidenote}{chapter}

%----------------------------------------------------------------------------------------

\begin{document}

%----------------------------------------------------------------------------------------
%	BOOK INFORMATION
%----------------------------------------------------------------------------------------

\titlehead{Some stuff about statistics}
\subject{Lecture notes for the ENS course of Statistics}

\title[Some stuff about Statistics]{Some stuff about Statistics}
% \subtitle{Customise this page according to your needs}

\author[St\'ephane Ga\"iffas"]{St\'ephane Ga\"iffas\thanks{}}

\date{\today}

\publishers{}

%----------------------------------------------------------------------------------------

\frontmatter % Denotes the start of the pre-document content, uses roman numerals

%----------------------------------------------------------------------------------------
%	OPENING PAGE
%----------------------------------------------------------------------------------------

%\makeatletter
%\extratitle{
%	% In the title page, the title is vspaced by 9.5\baselineskip
%	\vspace*{9\baselineskip}
%	\vspace*{\parskip}
%	\begin{center}
%		% In the title page, \huge is set after the komafont for title
%		\usekomafont{title}\huge\@title
%	\end{center}
%}
%\makeatother

%----------------------------------------------------------------------------------------
%	COPYRIGHT PAGE
%----------------------------------------------------------------------------------------

% \makeatletter
% \uppertitleback{\@titlehead} % Header

% \lowertitleback{
% 	\textbf{Disclaimer}\\
% 	You can edit this page to suit your needs. For instance, here we have a no copyright statement, a colophon and some other information. This page is based on the corresponding page of Ken Arroyo Ohori's thesis, with minimal changes.
	
% 	\medskip
	
% 	\textbf{No copyright}\\
% 	\cczero\ This book is released into the public domain using the CC0 code. To the extent possible under law, I waive all copyright and related or neighbouring rights to this work.
	
% 	To view a copy of the CC0 code, visit: \\\url{http://creativecommons.org/publicdomain/zero/1.0/}
	
% 	\medskip
	
% 	\textbf{Colophon} \\
% 	This document was typeset with the help of \href{https://sourceforge.net/projects/koma-script/}{\KOMAScript} and \href{https://www.latex-project.org/}{\LaTeX} using the \href{https://github.com/fmarotta/kaobook/}{kaobook} class.
	
% 	The source code of this book is available at:\\\url{https://github.com/fmarotta/kaobook}
	
% 	(You are welcome to contribute!)
	
% 	\medskip
	
% 	\textbf{Publisher} \\
% 	First printed in May 2019 by \@publishers
% }
% \makeatother

%----------------------------------------------------------------------------------------
%	DEDICATION
%----------------------------------------------------------------------------------------

% \dedication{
% 	The harmony of the world is made manifest in Form and Number, and the heart and soul and all the poetry of Natural Philosophy are embodied in the concept of mathematical beauty.\\
% 	\flushright -- D'Arcy Wentworth Thompson
% }

%----------------------------------------------------------------------------------------
%	OUTPUT TITLE PAGE AND PREVIOUS
%----------------------------------------------------------------------------------------

% Note that \maketitle outputs the pages before here

% If twoside=false, \uppertitleback and \lowertitleback are not printed
% To overcome this issue, we set twoside=semi just before printing the title pages, and set it back to false just after the title pages
\KOMAoptions{twoside=semi}
\maketitle
\KOMAoptions{twoside=false}

%----------------------------------------------------------------------------------------
%	PREFACE
%----------------------------------------------------------------------------------------

\chapter*{Preface}
\addcontentsline{toc}{chapter}{Preface} % Add the preface to the table of contents as a chapter


The aim of this course is, as the title indicated, to learn some stuff about statistics, and to try to exhibit some good looking mathematics from this field of applied mathematics, beyond convincing you that statistics are useful\sidenote{We won't list here, exhaustively, the numerous fields that make a regular use of mathematical statistics: marketing, medicine and more broadly health, finance, insurance, banking, etc.}

We will try to provide, all along the course, at material featuring 60\% of classical and unavoidable material from a course about statistics, and 40\% of more recent research results and some open questions.

The tentative agenda for the course is as follows:

\begin{itemize}
 	\item Modelization and the main statistical inference problems (estimation, confidence regions and tests)
 	\item Gaussian vectors and the Gaussian linear model
 	\item Theoretical guarantees and the optimality of least-squares
 	\item Estimation methods: methods of moments, maximum likelihood and other things
 	\item Exponential models and generalized linear models, logistic regression (optimal rates and some open questions)
 	\item Tests and multiple tests
 \end{itemize} 

% I am of the opinion that every \LaTeX\xspace geek, at least once during 
% his life, feels the need to create his or her own class: this is what 
% happened to me and here is the result, which, however, should be seen as 
% a work still in progress. Actually, this class is not completely 
% original, but it is a blend of all the best ideas that I have found in a 
% number of guides, tutorials, blogs and tex.stackexchange.com posts. In 
% particular, the main ideas come from two sources:

% \begin{itemize}
% 	\item \href{https://3d.bk.tudelft.nl/ken/en/}{Ken Arroyo Ohori}'s 
% 	\href{https://3d.bk.tudelft.nl/ken/en/nl/ken/en/2016/04/17/a-1.5-column-layout-in-latex.html}{Doctoral 
% 	Thesis}, which served, with the author's permission, as a backbone 
% 	for the implementation of this class;
% 	\item The 
% 		\href{https://github.com/Tufte-LaTeX/tufte-latex}{Tufte-Latex 
% 			Class}, which was a model for the style.
% \end{itemize}

% The first chapter of this book is introductive and covers the most 
% essential features of the class. Next, there is a bunch of chapters 
% devoted to all the commands and environments that you may use in writing 
% a book; in particular, it will be explained how to add notes, figures 
% and tables, and references. The second part deals with the page layout 
% and design, as well as additional features like coloured boxes and 
% theorem environments.

% I started writing this class as an experiment, and as such it should be 
% regarded. Since it has always been indended for my personal use, it may 
% not be perfect but I find it quite satisfactory for the use I want to 
% make of it. I share this work in the hope that someone might find here 
% the inspiration for writing his or her own class.

\begin{flushright}
	\textit{St\'ephane Ga\"iffas}
\end{flushright}


%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS & LIST OF FIGURES/TABLES
%----------------------------------------------------------------------------------------

\begingroup % Local scope for the following commands

% Define the style for the TOC, LOF, and LOT
%\setstretch{1} % Uncomment to modify line spacing in the ToC
%\hypersetup{linkcolor=blue} % Uncomment to set the colour of links in the ToC
\setlength{\textheight}{23cm} % Manually adjust the height of the ToC pages

% Turn on compatibility mode for the etoc package
\etocstandarddisplaystyle % "toc display" as if etoc was not loaded
\etocstandardlines % toc lines as if etoc was not loaded

\tableofcontents % Output the table of contents

% \listoffigures % Output the list of figures

% Comment both of the following lines to have the LOF and the LOT on different pages
% \let\cleardoublepage\bigskip
% \let\clearpage\bigskip

% \listoftables % Output the list of tables

\endgroup

%----------------------------------------------------------------------------------------
%	MAIN BODY
%----------------------------------------------------------------------------------------

\mainmatter % Denotes the start of the main document content, resets page numbering and uses arabic numbers
\setchapterstyle{kao} % Choose the default chapter heading style


\input{chap02_statistical_models}

\input{chap03_statistical_inference}

\input{chap04_linear_regression}

% \input{chap05_bayesian_statistics}


\setchapterpreamble[u]{\margintoc}
\chapter{Bayesian statistics}
\label{chap:bayesian_statistics}

Let us go back to the problems of statistical inference that we considered in Chapter~\ref{chap:statistical_inference}.
We have data $X$ valued on a measurable space $(E, \cE)$ and a model $\{ P_\theta : \theta \in \Theta\}$ for its distribution, see Definition~\ref{def:statistical_experiment} from Chapter~\ref{chap:statistical_models}.
For the problems of estimation and testing, we can define a set $A$ of \emph{decisions}: for scalar estimation, it is $A = \Theta \subset \R$, while for testing, we have binary decisions, so that $A = \{ 0, 1 \}$.

\section{Elements of decision theory} % (fold)
\label{sec:elements_of_decision_theory}

Given a (measurable) statistical procedure $\delta : E \go A$, we \emph{decide} $\delta(X) \in A$.
In order to assess a decision, we use a \emph{loss function} $\ell : A \times \Theta \go \R$.
This means that if the true parameter is $\theta \in \Theta$ and if we decide $a \in A$ then we incur a loss $\ell(a, \theta) \in \R$.

\begin{definition}
	Consider a statistical experiment with data $X \in E$ and a set of parameters $\Theta$, a set $A$ of decisions and a loss function $\ell : A \times \Theta \go \R$. The \emph{risk} of a statistical procedure $\delta : E \go A$ is given by
	\begin{equation*}
		R(\delta, \theta) = \E_\theta[ \ell(\delta(X), \theta)]
	\end{equation*}
	for any $\theta \in \Theta$.
\end{definition}

For the problem of estimation of a scalar parameter, we have $\Theta = \R = A$ and $\ell(\theta', \theta) = (\theta' - \theta)^2$, so that the risk is, in this case, the quadratic risk introduced in Definition~\ref{def:quadratic_risk} from Chapter~\ref{chap:statistical_inference}.
Note that we could consider other losses, such as $\ell(\theta', \theta) = |\theta' - \theta|^p$ for some $p \geq 1$.


Consider now statistical testing with hypotheses $H_0 : \theta \in \Theta_0$ and $H_1 : \theta \in \Theta_1$ where $\{ \Theta_0, \Theta_1 \}$ is a partition of $\Theta$.
Introduce the loss given by
\begin{equation}
	\label{eq:bayes-test-loss}
	\ell(i, \theta) = 0	\quad \text{if} \quad \theta \in \Theta_i \quad \text{ and } \quad \ell(i, \theta) = c_i \quad \text{if} \quad \theta \in \Theta_{1 - i}
\end{equation}
for $i \in \{ 0, 1 \}$ and constants $c_0, c_1 > 0$.
The risk writes in this case
\begin{equation*}
	R(\delta, \theta) =	c_i \P_\theta [\delta(X) = i] \quad \text{when} 
	\quad \theta \in \Theta_{1 - i}
\end{equation*}
for $i \in \{ 0, 1 \}$.
The constants $c_0, c_1 > 0$ allow to tune the importance given to the Type~I and Type~II errors: the approach described here leads to an approach of statistical testing different from the one described in Section~\ref{sec:tests}.


\section{Bayesian risk} % (fold)


Let us go back to the coin flip problem considered in Chapter~\ref{chap:statistical_inference}.
We observe $X_1, \ldots, X_n$ iid distributed as $\ber(\theta)$ for $\theta \in (0, 1)$.
The estimator we introduced back then was the empirical mean $\wh \theta_n = \bar X_n = n^{-1} \sum_{i=1}^n X_i$, and we know from~\eqref{eq:bernoulli-quadratic-risk} that the quadratic risk is given by $R(\wh \theta_n, \theta) = \theta (1 - \theta) / n$ for any $\theta \in (0, 1)$.
But what about the estimator $\wt \theta_n = 0$ ? It is a rather stupid estimator, but if $\theta$ is close to $0$, than it turns out to be a good estimator, and actually, it is easy to see that
$R(\wt \theta_n, \theta) < R(\wh \theta_n, \theta)$ whenever $\theta < 1 / (n + 1)$.
This proves that $\wt \theta_n = 0$ is better than $\wh \theta_n$, when assessed by the quadratic risk, for $\theta$ small enough.%
\sidenote{A longer story hides beneath this simple example: the Stein effect and the Stein estimator, which provably improves the sample average estimator using thresholding, see~\cite{stein1956inadmissibility,lehmann2006theory} for more details on this.}
This very simple example illustrates the fact that it is not possible to find an estimator with an optimal risk for all $\theta \in \Theta$.

%\todo{Exerice on Stein effect ?}

As illustrated above, given two statistical procedures $\delta, \delta'$ for the same problem of statistical inference, we do not have in general that $R(\delta, \theta) < R(\delta', \theta)$ uniformly for $\theta \in \Theta$.
What we can do instead is to consider an \emph{averaged risk}: choose a distribution $\mu$ on $\Theta$ and use it to integrate the risk over $\Theta$.
This distribution is called the \emph{prior distribution} or simply the \emph{prior}.
\begin{definition}[Bayesian risk]
	The Bayesian risk of a procedure $\delta$ associated to the \emph{prior} $\mu$ is given by
	\begin{equation*}
		R_B(\delta, \mu) = \int_{\Theta} R(\delta, \theta) \mu(d \theta) 
		= \int_{\Theta} \mu(d \theta) \int_E \ell(\delta(x), \theta) P_\theta(dx).
	\end{equation*}
\end{definition}
Note that $R_B(\delta, \mu) \leq \sup_{\theta \in \Theta} R(\delta, \theta)$ which means that the Bayes risk is always smaller than the worst-case risk over $\Theta$.
We understand this risk as an average of the risk over $\Theta$ ``weighted'' by the prior distribution $\mu$.
Given a prior $\mu$, the Bayesian risk is a scalar value: we can compare procedures using it and even try to find a procedure that minimizes it.%
\sidenote{We will do it in Section~\ref{sec:posterior_distribution_and_bayes_estimator}, such an estimator even has a name: it is a Bayesian estimator.}

\begin{example}
	For statistical testing with the loss given by~\eqref{eq:bayes-test-loss}, the Bayesian risk associated to a prior $\mu$ writes
	\begin{align*}
		R_B(\delta, \mu) = \sum_{i \in \{ 0, 1 \}} c_i \int_{\Theta_{1 - i}} \P_\theta[\delta(X) = i] \mu(d \theta),
	\end{align*}
	which is a weighted combination of the Type~I and Type~II errors averaged by the prior $\mu$.
\end{example}

Another interpretation of the Bayesian risk is of utmost important in Bayesian statistics.
Indeed, we could say that the parameter $\theta$ \emph{is itself a random variable} distributed as $\mu$, that we denote $T$ instead of $\theta$, and that $P_\theta$ is actually the distribution of $X$ ``conditionally'' on $T = \theta$.%
\sidenote[][*-3]{Of course the event $T = \theta$ has zero probability if $T$ is continuous with respect to the Lebesgue measure. We will explain clearly what such a \emph{conditional distribution} is in Section~\ref{sec:about_conditional_distributions_and_densities} below.}

Assuming that the joint distribution $P_{T, X}$ of $(T, X)$ is given by
\begin{align*}
	P_{T, X}[B \times C] = \P[ T \in B, X \in C] = \int_B \mu(d \theta) \int_C P_\theta(dx),
\end{align*}
we could write the Bayesian risk as an expectation with respect to $P_{T, X}$, since
\begin{equation*}
	R_B(\mu, \delta) = \int_{\Theta} \mu(d \theta) \int_E \ell(\delta(x), \theta) P_\theta(dx) = \E[ \ell(\delta(X), T)].
\end{equation*}
What we need to do now, in order to formalize this, is to explain what a conditional distribution is, and to explain some useful formulas, such as the Bayes formula for conditional densities.

\section{About conditional distributions and densities} % (fold)
\label{sec:about_conditional_distributions_and_densities}

Let $X$ and $Y$ be random variables on the same probability space and values in sets $\cX$ and $\cY$.
For any integrable function $f(X)$, we can define the conditional expectation $\E [f(X) | Y]$ as the random variable $g(Y)$ (for some measurable function $g$) which is unique almost surely, such that
\begin{equation}
	\E[f(X) h(Y)] = \E[ g(Y) h(Y)]
\end{equation}
for any measurable and bounded function $h$.
The particular value $g(y)$ of this conditional expectation is denoted $\E[f(X) | Y = y]$. 
In particular, we have that
\begin{align*}
	\E[f(X) h(Y) | Y] &= h(Y) \E[ f(X) | Y]
\end{align*}
almost surely and
\begin{align}
	\E [\E[ f(X) | Y]] = \E[f(X)].
\end{align}
Let us suppose now that the joint distribution $\P_{X, Y}$ of $X$ and $Y$ has a density $p(x, y)$ with respect to $\lambda \otimes \nu$ on $\cX \times \cY$.
We can define the marginal distributions of $X$ and $Y$ as
\begin{equation*}
	p_X(x) = \int_{\cY} p(x, y) \mu(dx), \quad
	p_Y(y) = \int_{\cX} p(x, y) \lambda(dy)
\end{equation*}
\todo{bon y'a des $\lambda$ qui est pris avant non ?}
which correpsond to the marginal distributions $\P_X$ and $\P_Y$ of $X$ and $Y$ so that
\begin{align*}
	\E[f(X)] &= \int_{\cX} f(x) P_X(dx) = \int_{\cX} f(x) p_X(x) \lambda(dx) \\ 
	\E[f(Y)] &= \int_{\cY} g(y) P_Y(dx) = \int_{\cY} g(y) p_Y(x) \nu(dy)
\end{align*}
for any $f, g$ such that $f(X)$ and $g(Y)$ are integrabel. \todo{attention $g$ c'est pas deja pris ?}
Let us remark that
\begin{align*}
	P_{X, Y} \big[ \{ y \in \cY : p_Y(y) = 0 \} \big] &= \int_{\cX \times \cY} \ind{p_Y(y) = 0} p(x, y) \lambda(dx) \nu(dy) \\
	&= \int_{y \in \cY : p_Y(y) = 0} \nu(dy) \int_{\cX} p(x, y) \lambda (dx) \\
	&= \int_{y \in \cY : p_Y(y) = 0} p_Y(y) \nu(dy) = 0
\end{align*}
namely $P_{X, Y}[ \{ y \in \cY : p_Y(y) = 0 \}] = 0$.
So, given any density $q$ we can define
\begin{equation*}
	p_{X | Y}(x | y) = \frac{p(x, y)}{p_Y(y)} \ind{p_Y(y) > 0} + k(x) \ind{p_Y(y) = 0},
\end{equation*}
so that any version of $p_{X | Y}$ associated to the choice of $q$ are all equal $P_{X, Y}$-almost surely, since we can check immediatly that $\int_{\cX} p_{X | Y}(x | y) \lambda(dx) = 1$, so that it is a probability density with respect to $\lambda$ on $\cX$.
Moreover, if we define
\begin{equation*}
	g(y) = \int_{\cX} f(x) p_{X | Y}(x | y) \lambda(dx)
\end{equation*}
we have for any measurable bounded function $h$, because of the Fubini theorem and using the fact that $\{y \in \cY : p_Y(y) = 0\}$ is a $P_{X, Y}$ -negligeable set that
\begin{align*}
	\E[ g(Y) h(Y)] &= \int_{\cY} g(y) h(y) p_Y(y) \nu(dy) \\
	&= \int_{\{ y \in \cY : p_Y(y) > 0 \}} h(y) p_Y(y) \nu(dy) \int_{\cX} f(x) \frac{p(x, y)}{p_Y(x)} \\
	&= \int_{\cX \times \cY} f(x) h(y) p(x, y) \lambda(dx) \nu(dy) \lambda (dx)
	&= \E[ f(X) h(Y)]
\end{align*}
warning $g$ is not any function but the function such that $g(Y) = \E[ f(X) | Y]$ almost surely.
which indeed corresponds to the definition ??? of $g(Y) = \E[f(X) | Y)$.

So, we proved that we can compute conditional expectation using the formula
\begin{equation*}
	\E[f(X) | Y] = \int_{\cX} f(x) p_{X | Y}(x | Y) \lambda(dx) = \int_{\cX} f(x) \P_{X | Y} (dx)
\end{equation*}
if we denote $P_{X | Y}$ as the distribution on $\cX$ fo,ction of $Y$ with density $p_{X | Y}(x | Y)$ with respect to $\lambda$. 
We can define in the say way $p_{X | Y}$ and $\P_{X | Y}$ uniquely on the set $\{ y : p_Y(y) > 0 \}$.
As explained above the complement $\{ y : p_Y(y) > 0 \}^\complement$ has mass equal to $0$: this has no iincidence since conditional expectation are themslef uniquely defined up to a negligable set .

We call $\P_{X | Y}$ the conditional distribution of $X$ conditionally on $Y$ and $p_{X | Y}(x | y)$ the density of $X$ ``conditionally on $Y=y$''. We can of couse define $P_{Y | X}$ and $p_{Y | X}$ exacly in the ame xay.
So, we end up with the fact that, by construction of these conditional densities, the density of the joint density $p_{X, Y}$ of $(X, Y)$  satisfies
\begin{equation}
	\label{eq:cond-density-formula}
	p_{X, Y}(x, y) = p_{X | Y}(x | y) p_Y(y) = p_{Y | X}(y | x) p_X(x)
\end{equation}
$P_{X, Y}$-almost surely.

\section{Posterior distribution and Bayes estimator} % (fold)
\label{sec:posterior_distribution_and_bayes_estimator}

We saw in ??? that the joint distribution $Q$ of $(T, X)$ is defined through its marginal distribution $g$ of $T$ and the conditional density $f(x | \theta)$ of $X$ conditionally on $T = \theta$ (hence the notation $f(x | \theta)$), so that
\begin{equation*}
	Q(d \theta, dx) = g(\theta) f(x | \theta) (\lambda \otimes \nu) (d\theta, dx). 	
\end{equation*} 
The marginal density $\bar f$ of $X$ can be obtained by integrating with respect to $\theta$:
\begin{equation*}
	\bar f(x) = \int_{\Theta} f(x | \theta) g(\theta) \lambda(d \theta)
\end{equation*}
and the conditional density of $T | X = x$ can therefore we written as
\begin{equation*}
	g(\theta | x) = \frac{f(x | \theta) g(\theta)}{\bar f(x)} = \frac{f(x | \theta) g(\theta)}{\int_{\Theta} f(x | \theta') g(\theta') \lambda(d \theta')}.
\end{equation*}
If is the density of the conditional distribution denoted $Q_x$ of $T | X = x$.
We simply used here the \emph{Bayes formula} on conditional densities in order to reverse the order of the conditionning: we expressed $T | X$ from $X | T$ since the distribution of $X | T$ is specified by the model we considered

\begin{definition}
	We call $\mu = g \cdot \lambda$ the \emph{prior} distribution we call the conditional distribution $Q_x$of $T | X=x$ the \emph{posterior} distribution or simply \emph{posterior}.
\end{definition}

The Bayesian reasoning is therefore as follows: we choose a prior on $\theta$, and we compute the posterior using the data. 
A nice aspect of this approach is that we can quantify uncertainty right out of the box with such an approach since instead of producing a point estimatpr $\wh \theta_n$ in the \emph{frequentist} approach (what we did in Section???) we produce a full posterior distribution $Q_x[\cdot] = \P[T \in \cdot | X = x]$.

\paragraph{Bayes estimator.} % (fold)


In that case we can write

where the expectation is computed with respect to the joint distribution of $(T, X)$, namely integration with respect to $Q$ defined by

We do ``as if'' $\theta$ where random and with distribution $\mu$.
The distribution $P_\theta$ becomes the conditional distribution of $X | T = \theta$, namely
\begin{equation*}
	P_\theta[A] = \E [\ind{A}(X) | T = \theta],
\end{equation*}
or even $P_T[A] = \E [\ind{A}(X) | T]$.

In what follows, we will assume that we have a dominating measure $\lambda$ on $\Theta$ such that $\mu = g \cdot \lambda$ where $g$ is the density of $T$ on $\Theta$ with resoect tp $\lambda$ (often $\lambda$ is the lEbuesgue measure).
We suppose also that thre is a measure $\nu$ on $E$ for which $P_\theta = f(\cdot | \theta) \cdot \nu$ where similarly $\frac{d P_\theta}{d \nu} = f(x | \theta)$. 
We use here the notation $f(\cot | \theta)$ instead of $f_\theta$ to stress that it will correspond to a conditional density.
We need at this point to classify things about conditional distributions and conditional densities.


Let us consider the estimation problem where $A = \Theta$ and let us use the Bayes risk as a measure to assess the error of a procedure $\delta : E \go \Theta$.
An optimal Bayesian estimator should minimize the Byaes risk. 
Another beautiful aspect of this Bayesian approach is that the minimizer of the Byaes risk can be made explitic, since using Fubini toghther with thre fact that $f(x | \theta) g(\theta) = g(\theta | x) \bar f(x)$ almost surely, we can rewrite the Bayes risk as follows:
\begin{align*}
	R_B(\mu, \delta) &= \int_{\Theta} \int_E \ell(\theta, \delta(x)) g(\theta | x) \bar f(x) \nu(dx) \lambda(d \theta) \\
	&= \int_E \bar f(x) \nu(dx) \int_{\Theta} \ell(\theta, \delta(x)) g(\theta | x) \lambda(dx) \\
	&=  \int_E \bar f(x) \nu(dx) \int_{\Theta} \ell(\theta, \delta(x)) Q_x(d \theta).
\end{align*}
We is remarkable is that in order to minimize this quantity, we need to minimize for any fixed $x \in E$ the quantity
\begin{equation*}
	\int_{\Theta} \ell(\theta, \delta(x)) Q_x(d \theta) = \E_{Q_x} [\ell(T, \delta(x))] 
	= \E [\ell(T, \delta(X)) | X = x],
\end{equation*}
namely the expectation of the loss with respect to the posterior distribution $Q_x$ of $T | X = x$.
\begin{definition}
	Any estimator $\wh \theta(X)$ (not necessarily unique) defined as 
	\begin{equation*}
		\wh \theta_(x) \in \argmin_{t \in \Theta} \int_{\Theta} \ell(\theta, t) Q_x(d \theta) 
		= \argmin_{t \in \Theta} \E_{Q_x} [\ell(T, t) ],
	\end{equation*}
	namely a minimizer of the loss averaged by the posterior distribution is called a \emph{Bayes} or \emph{Bayesian estimator} associated to the prior $\mu = g \cdot \lambda$ and to the loss $\ell$.
\end{definition}

WHenever $\ell(\theta, \theta') = (\theta - \theta')^2$ then
\begin{equation*}
	\argmin_{t \in \R} \E_{Q_x}[ (T - t)^2] = \E_{Q_x}[T]
\end{equation*}
namely the \emph{Bayes estimator with the quadratic loss is the expectation of the posterior distribution.}
If $\ell(\theta, \theta') = |\theta - \theta'|$ then 
\begin{equation*}
	\argmin_{t \in \R} \E_{Q_x}[ |(T - t| ] = \med(Q_x) = F_{Q_x}^{-1}(1/2),
\end{equation*}
namely the Bayes estimator associated to the $\ell_1$ loss is given by the median of the posterior distribution. \todo{exo proof etc}

\begin{recipe}
	On simple examples, we can compute explicitly the Bayes estimator. Given the data density $f(x | \theta)$ and  the prior density $g$, we simply wrte the joint distribution of $(T, X)$ and use the fact that the posterior density is a density, namely it must integrate with respect to $\theta$ to $1$:
	\begin{equation*}
		g(\theta | x) = \mathrm{constant}(x) f(x | \theta) g(\theta)
	\end{equation*}
	where $\mathrm{constant}(x) =  1 / \int_\Theta f(x | \theta) g(\theta) \lambda(d \theta)$, so that we can identify the posterior distribution with a carefull look, and ideally some coffee at the formula fpr $f(x | \theta) g(\theta)$ and identify a density with respect to $\theta$.
\end{recipe}

Let us give some standard examples of prior and data distribution wuth that the prior can be made epxlicit .


Consider the data distribution $X \sim \bin(n, \theta)$ and with prior $\uni([0, 1])$ on $\theta$. This means that $X | T = \theta$ has density
\begin{equation*}
	f(x | \theta) = \binom{n}{x} \theta^x (1 - \theta^{n-x} \ind{\{ 0, \ldots, n\}}(x)	
\end{equation*}
with respect to the counting measure $\nu$ on $\N$ and that the prior distribution has density $g(\theta) = \ind{[0, 1]}(\theta)$ wuth respect to the Lebuesgye measure $\lambda$ on $\R$, so that the joint distribition of $(T, X)$ has density
\begin{equation*}
	f(\theta, x) = \binom{n}{x} \theta^x (1 - \theta)^{n - x} \ind{[0, 1]}(\theta) 
	\ind{\{ 0, \ldots, n\}}(x)
\end{equation*}
with respect to the product measure $\lambda \otimes \nu$. THe posterior distribution, namely the distriution of $T | X=x$ is therefore proportional to $\mapsto \theta^x (1 - \theta)^{n - x} \ind{[0, 1]}(\theta)$. We recognize the $\bet(a, b)$ distribution ???, that as density
\begin{equation*}
	\frac{1}{\beta(a, b)} t^{a-1} (1 - t)^{b-1} \ind{[0, 1]}(t)
\end{equation*}
where we recall that $\beta(a, b) = \int_0^1 t^{a-1} (1 - t)^{b-1} d t = \Gamma(a) \Gamma(b)  / \Gamma(a + b)$.
Therefore, we have that the posterior distribution is given by
\begin{equation*}
	Q_x = \bet(x + 1, n - x + 1).
\end{equation*}
Also, we have that
\begin{equation*}
	\E[Z^k] = \frac{\beta(a + k, b)}{\beta(a, b)} = \frac{\Gamma(a + k) \Gamma(a + b)}{\Gamma(a + k + b) \Gamma(a)} = \frac{a (a + 1) \cdots (a + k -1)}{(a + b) (a + b + 1) \cdots (a + k + b - 1)}
\end{equation*}
\todo{cjeck formula}. In aprticualr we get whenver $B \sim \bet(a, b)$ that
\begin{equation*}
	\E[Z] = \frac{a}{a + b} \quad \text{and} \quad \var[Z] = \frac{ab}{(a + b)^2 (a + b + 1)}.
\end{equation*}
So, using ???, the Bayes estimator of $\theta$ for the quadratic loss is given by 
\begin{equation*}
	\E_{Q_x}[T | X=x] = \E[ \bet(x+1, n - x + 1)] = \frac{x + 1}{n + 2},
\end{equation*}
\todo{formula c'est ok comem ca?}
namely
\begin{equation*}
	\wh \theta_n^B = \frac{X + 1}{n + 2},
\end{equation*}
which is an estimator different from $\wh \theta_n = X / n$, the one we use in Section~???.
The quadratic risk of $\wh \theta_n^B$ is, using the bias-variance formula from ??? given by
\begin{align*}
	\E_\theta[ (\wh \theta_n^B - \theta)^2] &= \var_\theta[\wh \theta_n^B] + (\E_\theta[\wh \theta_n^B] - \theta)^2 \\
	&= \frac{n \theta(1 - \theta)}{(n + 2)^2} + \Big( \frac{1 - 2 \theta}{n + 2} \Big)^2 = \frac{(1 - 2 \theta)^2 + n \theta (1 - \theta)}{(n+2)^2}
\end{align*}
and the Bayes ris can be computed as 
\begin{equation*}
	\int_0^1 \Big( \frac{1 - 2 \theta}{n + 2} \Big)^2 = \frac{(1 - 2 \theta)^2 + n \theta (1 - \theta)}{(n+2)^2} d \theta = ???
\end{equation*}
\todo{une facton plus direct de le calculer ?}


Followingn Example ? it is easy to see that if the prior is $\beta(a, b)$ and the data distribution
\todo{define clearly data distributin } si $\bin(n, \theta)$ then the posterio distribution is $\bet(a + x - 1, b + n - x + 1)$. Note that for this example the prior and posterior belong to the same family of $\bet$ distributions. In such a case, we say the the $\bin$ and $\bet$ distributions are conjuguate distributions: computations cna be made explicit in such case.
Note that however, this is not often the case and BLALBA
The more general case is the Dirichlet / Multinomial distributions, that we leave as an exercice.

\todo{dire aussi qu'on peut noter abusiement $\theta \sim ???$}
Another classical example is with the Gaussian distribution.
Consider data $X_1, \ldots, X_n$ iid with distribution $\nor(\theta, \sigma^2)$ and prior $\theta \sim \cN(0, \tau^2)$.
Let us find out the posterior distribution in this case
\begin{align*}
	f_{X | T}(x | \theta) g(\theta) &= c(\sigma) \exp\Big( - \frac{1}{2 \sigma^2} \sum_{i=1}^n (x_i - \mu)^2 - \frac{\mu}{\tau^2} \Big) \\
	&= c(\sigma) \exp \Big (  -\Big( \frac{1}{2 \gamma} \mu^2 + \frac{\mu}{\sigma^2} \sum_{i=1}^n x_i + c(x_1, \ldots, x_n) \Big)  \Big ) \\
	&= c(\sigma) \exp \Big( -\Big( \frac{1}{2 \gamma} \Big( \mu -  \frac{\mu}{\sigma^2} \sum_{i=1}^n x_i 
	\Big)^2 + c(x_1, \ldots, x_n) \Big)  \Big )
\end{align*}
where we put $\gamma = 1 / (n / \sigma^2 + 1 / \tau^2) = \sigma^2 / (n + \sigma^2 / \tau^2)$ and where $c$ stands for uninteresing constants which entails that the posterior distribution is
\begin{equation*}
	\nor\Big( \frac{\mu}{\sigma^2} \sum_{i=1}^n x_i, \sigma^2 / (n + \sigma^2 / \tau^2) \Big)
\end{equation*}
so that the Bayes estimator for the quadratic risk is given by 
\begin{equation*}
	\wh \theta_n^B = \frac{1}{n + \sigma^2 / \tau^2} \sum_{i=1}^n X_i.
\end{equation*}
This entails also that the Gussian distribuion is conjuguated to itself.

Another very interesting example is the Gaussian linear regression model we considered in Chapter ??? where
$Y_i = X_i^\top \theta + \eps_i$ with deterministic $X_i \in R^d$ (or everythin is doe conditionally on them) and $\eps_i \sim \nor(0, \sigma^2)$ and iid.
In the Gaussian linear regression setting, we have that $\by \sim \nor(\bX \theta, \sigma^2 \bI)$ where we recall that $\by$ $\bX$ are given by ????.
We consider this in a Bayesian setting by assuming that $\by | T = \theta = \nor(\bX \theta, \sigma^2 \bI)$ and by considering the prior distribution $\theta \sim \nor(0, \frac{1}{\lambda} \bI_d)$.
The joint distribution of $(\by, T)$ is, therefor, given by
\begin{equation*}
	f_{\by | T = \theta}(y | \theta) g(\theta) = \frac{1}{(\sigma \sqrt{2 \pi})^{n}} 
	\exp \Big( -\frac{1}{2 \sigma^2} \norm{\by - \bX \theta}^2 - \frac {\lambda}{2} \norm{\theta}^2 \Big).
\end{equation*}
What is, in this setting, the posterior distribution $\P_{\theta | \by}$ ?
\todo{ en fait c'est chiant, on a vraiment envie de simplifier ces putain de notations de merde}
This is somewhat more complicated then what we did in both previous examples, and we need the following theorem about the multivatiate Gaussian distribution to handle this example.
\begin{theorem}
	Consider two matrices $\bLambda \succ 0$ and $\bL \succ 0$ and consider 
	$X$ such that $\P_X = \nor(\mu, \bLambda^{-1})$ and $Y$ such that $\P_{Y | X = x} = \nor(\bA x + b, \bL^{-1})$. Then, we have the following:
	\begin{equation*}
		\P_Y \sim \nor( \bA \mu + b, \bL^{-1} + \bA \bLambda^{-1} \bA^\top)		
	\end{equation*}
	and
	\begin{equation*}
		\P_{X | Y = y} = \nor(\bSigma (\bA^\top \bL (y - b) + \bLambda \mu), \bSigma)
	\end{equation*}
	where $\bSigma = (\bLambda + \bA^\top \bL \bA)^{-1}$.
\end{theorem}
The proof of this results can be found in ???? Bishop ??? dire endroit exact.
This is a computational proves that makes heavy use of ???
 The proof is given in ???
In the case that interests us we have $\mu = 0$, $\bLambda^{-1} = \bI_d / \lambda$, $\bLambda = \lambda \bI_d$, $\bL^{-1} = \sigma^2 \bI_n$, $\bA = \bX$ and $b = 0$ so that
\begin{equation*}
	\bSigma = \Big( \lambda \bI_d + \frac{1}{\sigma^2} \bX^\top \bX \Big)^{-1} = \sigma^2 \Big( \bX^\top \bX  + \lambda \sigma^2 \Big)
\end{equation*}
so that the posterior is given by
\begin{equation*}
	\P_{\theta | \by} = \nor \Big( (\bX^\top \bX  + \lambda \sigma^2 \bI_d)^{-1} \bX^\top \by,
	\sigma^2 (\bX^\top \bX + \lambda \sigma^2 \bI_d)^{-1} \Big)
	 \Big)
\end{equation*}
and the Bayes estimator for the quaradtic risk writes
\begin{equation*}
	\wh \theta_n^B = (\bX^\top \bX  + \lambda \sigma^2 \bI_d)^{-1} \bX^\top \by.
\end{equation*}
In this example, the Bayes estimator coincides with the so-called MAP estimator (maximum a posterior), which is given by, when it exists, the mode of the posterior, since the Gaussian distribution is symmetrical.
Indeed, the posterior distribugion is propoertional to
\begin{equation*}
	\exp \Big( -\frac{1}{2 \sigma^2} \norm{\by - \bX \theta}^2 - \frac{\lambda}{2} \norm{\theta}^2 \Big)
\end{equation*}
so that maximizing this function with respect to $\theta$ corresponds to minimizing
\begin{equation*}
	F(\theta) = \norm{\by - \bX \theta}^2 + \sigma^2 \lambda \norm{\theta}^2.
\end{equation*}
The function $F$ is strongly convex, since its Hessian satisfies $\nabla^2 F(\theta) = 2 \bX^\top \bX + 2\sigma^2 \lambda \bI_d \mgeq \sigma^2 \lambda \bI_d \succ 0$.
So, its minimizers must cancel out its gradient
\begin{equation*}
	\nabla F(\theta) = 2 \bX^\top (\bX \theta - \by) + 2 \sigma^2 \lambda \theta,
\end{equation*}
and therefore equals
\begin{equation*}
	\wh \theta_n = (\bX^\top \bX + 2 \sigma^2 \lambda \bI_d)^{-1} \bX^\top \by.
\end{equation*}
Note that this corresponds to a \emph{regularized} or \emph{penalized} version of the least-squares estimator 
since
\begin{equation*}
	\wh \theta_\lambda = \argmin_{\theta \in \R^d} \Big( \norm{\by - \bX \theta}^2 + \pen(\theta) \Big),
\end{equation*}
with $\pen(\theta) = \sigma^2 \lambda \norm{\theta}^2$ is called the \emph{ridge penalization}.
This penalization avoid the parameters, also called the \emph{model weights} to take large values, and is the most widely used form of penalization in statistics and machine learning (and is used way beyond the least-squares regression problem considered here).
\todo{also tikonov regularization blabla}
What we proved is that, for the Gaussian linear model, a Gaussian prior on the model weights acts exactly as a penalization term, forbidding these weights to be complextely \emph{free} (in eventually take arbitrary large values, when the conditioning of $\bX$ is bad, for instance). The variance term of the prior $\theta \sim \nor(0, \lambda^{-1} \bI_d)$ is parametrized by $\lambda > 0$: whenever $\lambda$ is small, then the prior is almost "flat" and the penalization in ??? is small: we expect in this case $\wh \theta_\lambda$ to be close to the least-squares estimator $\wh \theta_n$ (and $\wh \theta_\lambda = \wh \theta$ whenever $\lambda  = 0$). On the other hand, if $\lambda$ is large, the prior is highly concentrated around $0$, which is equivaluent to a strong penalization in ???


\section{Proofs} % (fold)
\label{sec:sec:chap05_proofs}


\subsection{Proof of the minimax lower bound ???} % (fold)
\label{sec:proof_of_the_minimax_lower_bound_}

Now, we have all the tools to prove the lower bound side of Theorem~??? namely that 
\begin{equation}
	\inf_{\wh \theta} \sup_{P \in \cG(P_X, \sigma^2)} \E_P \norm{\wh \theta - \theta}^2 \geq \frac{\sigma^2}{n} \E [ (\wt \bSigma)^{-1}] = \frac{\sigma^2}{n} \E [ (\wt \bSigma)^{-1}] = \frac{\sigma^2}{n} \E [ (\bSigma^{-1/2} \wh \bSigma \bSigma^{-1/2})^{-1}].
\end{equation}
Let us recall recall that in the setting of Theorem~??? we have $(X_1, Y_1), \ldots, (X_n, Y_n)$ iid and that $\cG(P_X, \sigma^2)$ is the set of joint distribution on $(X, Y)$ satisfying $X \sim P_X$, $Y = X^\top \theta^* + \eps$ almost surely and $\eps$ independent of $X$ and such that $\eps \sim \nor(0, \sigma^2)$.
Let us recal that the excenss risk si given by $\cE(\wh \theta) = R(\wh \theta) - R(\theta) = \norm{\wh \theta - \theta}_{\bSigma}^2$ and that $\bSigma = \E[X X^\top] \succ 0$ with $R(\theta) = \E[(Y - X^\top \theta)^2]$.

First, let us remark that $\sup_{P \in \cG(P_X, \sigma^2)}$ corresponds to $\sup_{\theta^* \in \Theta}$ denoting $\P_{\theta^*} = P_{X, Y}$ and let us denote also $\E_{\theta^*}$, so that we can to lower bound
\begin{equation*}
	\inf_{\wh \theta} \sup_{\theta \in \Theta} \E_\theta \norm{\wh \theta - \theta}_{\bSigma}^2.
\end{equation*}
The first, and certainly main trick, is to lower bound this minimax risk by the Bayes risk. Let us choose some prior distribution $\Pi$ for $\theta$ and write
\begin{align}
	\nonumber
	\inf_{\wh \theta} \sup_{\theta \in \Theta} \E_\theta \norm{\wh \theta - \theta}_{\bSigma}^2 
	&\geq \inf_{\wh \theta} \int_{\R^d} \E_\theta \norm{\wh \theta - \theta}_{\bSigma}^2 \Pi(d \theta) \\
	\label{eq:ls-bayes-risk}
	&= \inf_{\wh \theta} \E_{\theta \sim \Pi} \E_\theta \norm{\wh \theta - \theta}_{\bSigma}^2.
\end{align}
All the following computations are performed conditionally on $X_1, \ldots, X_n$ inside the expectations.
The distribution of $\by | \theta$ is $\nor(\bX \theta, \sigma^2 \bI_n)$. We choose the prior distribution
\begin{equation*}
	\theta \sim \Pi_\lambda := \nor\Big( 0, \frac{\sigma^2}{\lambda n} \bI_d \Big)
\end{equation*}
which corresponds to what we did in Exercice ??? with $\lambda' = n \lambda / \sigma^2$.
So we know, using this exerice, that 
\begin{equation*}
	\theta | \by \sim \nor\Big( \wh \theta_\lambda, \frac{\sigma^2}{n} (\bX^\top \bX + \lambda \bI_d)^{-1} \Big)
\end{equation*}
where
\begin{equation*}
	\wh \theta_\lambda = (n^{-1} \bX^\top \bX + \lambda \bI_d)^{-1} \bX^\top \by = \argmin_{\theta \in \R^d} \Big( \frac 1n \norm{\by - \bX \theta}^2 + \lambda \norm{\theta}^2 \Big).
\end{equation*}
is the ridge-penalized least squares estimator from ???.
The second trick is that we know how to minimize the Bayes risk~\eqref{eq:ls-bayes-risk}: it can be minimized by looking for
\begin{equation*}
	\wh \theta^B \in \argmin_{\theta' \in \R^d} \int_{\R^d} \norm{\theta' - \theta}_{\bSigma}^2 \Pi_{\theta | \by}(d \theta),
\end{equation*}
which is the average of the loss function with respect to the posterior distribution $\Pi_{\theta | \by}$, as explained in ???.
But, let us remakr that if $Z$ is a random vector such that $\E \norm{Z}^2 < \infty$, then the function $F : \R^d \go \R^+$ given by $F(t) = \E \norm{Z - t}^2$ is minimized at $t^* = \E[Z]$ whenever $\Sigma \succ 0$
\todo{proof en marge}.
This entails that here, the Bayes estimator is indeed
\begin{equation*}
	\wh \theta_\lambda = \Big( \frac 1n \bX^\top \bX + \lambda \bI_d\Big)^{-1} \bX^\top \by
\end{equation*}
and we end up, by combining ??? and ??? to the lower bound 
\begin{align*}
	\inf_{\wh \theta} \sup_{\theta \in \Theta} \E_\theta \norm{\wh \theta - \theta}_{\bSigma}^2 &\geq 
	\int_{\R^d} \E_\theta \norm{\wh \theta_\lambda - \theta}_{\bSigma}^2 \Pi_\lambda(d \theta) \\
	&= \E_{\theta \sim \Pi_\lambda} \E_\theta [\cE(\wh \theta_\lambda)] 
\end{align*}
on the minimax risk, for any $\lambda > 0$, that we are able to compute exactly, thanks to the next Lemma.
Let us recall that $\wh \bSigma = n^{-1} \bX^\top \bX = n^{-1} \sum_{i=1}^n X_i X_i\top$ and introduce $\wh \bSigma_\lambda = \wh \bSigma + \lambda \bI_d$.
\begin{lemma}
	\label{lem:excess_risk_ridge}
	The excess risk of the ridge estimator $\wh \theta_\lambda$ given by ? equals
	\begin{equation*}
		\E [\cE(\wh \theta_\lambda)] = \lambda^2 \E \norm{\theta^*}_{(\wh \bSigma_\lambda)^{-1} \bSigma (\wh \bSigma_\lambda)^{-1}}^2 + \frac{\sigma^2}{n} \E \tr \Big( (\wh \bSigma_\lambda)^{-1} \bSigma (\wh \bSigma_\lambda)^{-1} \wh \bSigma \Big)
	\end{equation*}
	under the assumption that $Y_i = X_i^\top \theta^* + \eps_i$ for $\eps_i \sim \nor(0, \sigma^2)$.
\end{lemma}
We inject the formula given by Lemma~\ref{lem:excess_risk_ridge} in ??? to end up with the lower bound
\begin{equation*}
	\E_{\theta^* \sim \Pi_\lambda} \Big[ \lambda^2 \E \norm{\theta^*}_{(\wh \bSigma_\lambda)^{-1} \bSigma (\wh \bSigma_\lambda)^{-1}}^2  + \frac{\sigma^2}{n} \E \tr \Big( (\wh \bSigma_\lambda)^{-1} \bSigma (\wh \bSigma_\lambda)^{-1} \wh \bSigma \big) \Big].
\end{equation*}
So, using Fubini, and since $\E_{\theta^* \sim \Pi_\lambda} [\theta^* (\theta^*)^\top] = \frac{\sigma^2}{\lambda n} \bI_d$ by definition of $\Pi_\lambda$, we end up with
\begin{align*}
	\E_{\theta^* \sim \Pi_\lambda} \Big[ \lambda^2 & \E \norm{\theta^*}_{(\wh \bSigma_\lambda)^{-1} 
	\bSigma (\wh \bSigma_\lambda)^{-1}}^2 \Big] \\
	&= \lambda^2 \; \E \; \E_{\theta^* \sim \Pi_\lambda} \tr \Big[ (\theta^*)^\top (\wh \bSigma_\lambda)^{-1} \bSigma (\wh \bSigma_\lambda)^{-1} \theta^* \Big] \\
	&= \lambda^2 \; \E \; \E_{\theta^* \sim \Pi_\lambda} \tr \Big[(\wh \bSigma_\lambda)^{-1} \bSigma (\wh \bSigma_\lambda)^{-1} \theta^*  (\theta^*)^\top \Big] \\
	&= \frac{\sigma^2}{n} \; \E \tr \Big[(\wh \bSigma_\lambda)^{-1} \bSigma (\wh \bSigma_\lambda)^{-1}
	\lambda \bI_d \Big]
\end{align*}
where we used $\tr[x] = x$ for $x \in \R$ in the second line ???? so that the minimization becomes now
\begin{equation*}
	\frac{\sigma^2}{n} \E \tr \Big[ (\wh \bSigma_\lambda)^{-1} \bSigma (\wh \bSigma_\lambda)^{-1} (\wh \bSigma + \lambda \bI_d) \Big] = \frac{\sigma^2}{n} \E \tr \big[ (\wh \bSigma_\lambda)^{-1} \bSigma \big].
\end{equation*}
So, we proved that for any $\lambda > 0$ we have the lower bound
\begin{equation*}
	\inf_{\wh \theta} \sup_{\theta \in \Theta} \E_\theta \norm{\wh \theta - \theta}_{\bSigma}^2 \geq
	\frac{\sigma^2}{n} \E \tr \big[ (\wh \bSigma_\lambda)^{-1} \bSigma \big]
\end{equation*}
for any $\lambda > 0$.
Since $P_X$ is non-degenerate, we know that $\wh \Sigma \succ 0$ almost surely and furthermore the function 
\begin{equation*}
	\lambda \mapsto \tr \big[ (\wh \bSigma + \lambda \bI_d)^{-1} \bSigma \big] 
	= \tr \big[ (\bSigma^{-1/2} \wh \bSigma \bSigma^{-1/2} + \lambda \bSigma^{-1})^{-1} \big]
\end{equation*}
is decreasing on $(0, +\infty)$ since $\lambda_2 \bSigma^{-1} \succ \lambda_1 \bSigma^{-1}$ whenever $\lambda_2 > \lambda_1$ and is positive, so that by monotone convergence we have indeed that
\begin{equation*}
	\E \tr \big[ (\wh \bSigma_\lambda)^{-1} \bSigma \big] \go 
	\E \tr \big[ (\wh \bSigma)^{-1} \bSigma \big] = \E \tr \big[ (\wt \bSigma)^{-1} \big]
\end{equation*}
as $\lambda \go 0^+$.
This proves the lower bound stated in Theorem~? up to the proof of Lemma~\ref{lem:excess_risk_ridge}.

\paragraph{Proof of Lemma~\ref{lem:excess_risk_ridge}.}

Let us recall that $Y_i = X_i^\top \theta^* + \eps_i$ with $\eps_i | X_i \sim \nor(0, \sigma^2)$ ($\eps_i$ are independent of $X_i$).
We have
\begin{equation*}
	\frac 1n \sum_{i=1}^n Y_i X_i = \frac 1n \sum_{i=1}^n X_i X_i^\top \theta^* 
	+ \frac 1n \sum_{i=1}^n \eps_i X_i = \wh \bSigma \theta^* + \frac 1n \sum_{i=1}^n \eps_i X_i,
\end{equation*}
so that
\begin{equation*}
	\E_{\theta^*} [\cE(\wh \theta_\lambda)] 
	=  \E_{\theta^*} \norm{\wh \theta_\lambda - \theta^*}_{\bSigma}^2 
	= \E \Big\| (\wh \bSigma_\lambda)^{-1} \Big(\wh \bSigma \theta^* + \frac 1n \sum_{i=1}^n \eps_i X_i \Big) - \theta^* \Big\|_{\bSigma}^2 
\end{equation*}
but using $(\wh \bSigma_\lambda)^{-1} (\wh \bSigma + \lambda \bI_d - \lambda \bI_d) = \bI_d - \lambda 
(\wh \bSigma_\lambda)^{-1}$ we obtain
\begin{align*}
	\E_{\theta^*} [\cE(\wh \theta_\lambda)] &= \E \Big\| (\wh \bSigma_\lambda)^{-1} \frac 1n \sum_{i=1}^n \eps_i X_i - \lambda (\wh \bSigma_\lambda)^{-1} \theta^* \Big\|_{\bSigma}^2 \\
	&= \E \bigg[ \E \bigg[ \Big\| \frac 1n \sum_{i=1}^n \eps_i X_i - \lambda \theta^* \Big\|_{(\wh \bSigma_\lambda)^{-1} \bSigma (\wh \bSigma_\lambda)^{-1}}^2 \bigg| X_1, \ldots, X_n \bigg] \bigg] \\
	&= \E \bigg[ \E \bigg[ \Big\| \frac 1n \sum_{i=1}^n \eps_i X_i \Big\|_{(\wh \bSigma_\lambda)^{-1} \bSigma (\wh \bSigma_\lambda)^{-1}}^2 \bigg| X_1, \ldots, X_n \bigg] \bigg]  + \lambda^2 \E \norm{\theta^*}_{(\wh \bSigma_\lambda)^{-1} \bSigma (\wh \bSigma_\lambda)^{-1}}^2 \\
	&= \frac{\sigma^2}{n^2} \E \bigg[ \sum_{i=1}^n \norm{X_i}_{(\wh \bSigma_\lambda)^{-1} \bSigma (\wh \bSigma_\lambda)^{-1}}^2 \bigg]  + \lambda^2 \E \norm{\theta^*}_{(\wh \bSigma_\lambda)^{-1} \bSigma (\wh \bSigma_\lambda)^{-1}}^2,
\end{align*}
where we used repeatedly that $\E[\eps_i | X_1, \ldots, X_n] = 0$, $\E[\eps_i \eps_j | X_1, \ldots, X_n] = 0$ for any $i \neq j$ and $\E[\eps_i^2 | X_1, \ldots, X_n] = \sigma^2$.
But 
\begin{align*}
	\frac 1n \sum_{i=1}^n \norm{X_i}_{(\wh \bSigma_\lambda)^{-1} \bSigma (\wh \bSigma_\lambda)^{-1}}^2 
	&= \frac 1n \sum_{i=1}^n \tr \Big[ (\wh \bSigma_\lambda)^{-1} \bSigma (\wh \bSigma_\lambda)^{-1} X_i X_i^\top \Big] \\
	&= \tr \big[ (\wh \bSigma_\lambda)^{-1} \bSigma (\wh \bSigma_\lambda)^{-1} \wh \bSigma \big],
\end{align*}
which concludes the proof of Lemma~\ref{lem:excess_risk_ridge}.



\input{chap06_mle_exponential_models}


% section exponential_models (end)

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

% The bibliography needs to be compiled with biber using your LaTeX editor, or on the command line with 'biber main' from the template directory

% \defbibnote{bibnote}{Here are the references in citation order.\par\bigskip} % Prepend this text to the bibliography
\printbibliography[heading=bibintoc, title=Bibliography] % Add the bibliography heading to the ToC, set the title of the bibliography and output the bibliography note

%----------------------------------------------------------------------------------------
%	NOMENCLATURE
%----------------------------------------------------------------------------------------

% The nomenclature needs to be compiled on the command line with 'makeindex main.nlo -s nomencl.ist -o main.nls' from the template directory

% \nomenclature{$c$}{Speed of light in a vacuum inertial frame}
% \nomenclature{$h$}{Planck constant}

% \renewcommand{\nomname}{Notation} % Rename the default 'Nomenclature'
% \renewcommand{\nompreamble}{The next list describes several symbols that will be later used within the body of the document.} % Prepend this text to the nomenclature

% \printnomenclature % Output the nomenclature

%----------------------------------------------------------------------------------------
%	GREEK ALPHABET
% 	Originally from https://gitlab.com/jim.hefferon/linear-algebra
%----------------------------------------------------------------------------------------

% \vspace{1cm}

% {\usekomafont{chapter}Greek Letters with Pronounciation} \\[2ex]
% \begin{center}
% 	\newcommand{\pronounced}[1]{\hspace*{.2em}\small\textit{#1}}
% 	\begin{tabular}{l l @{\hspace*{3em}} l l}
% 		\toprule
% 		Character & Name & Character & Name \\ 
% 		\midrule
% 		$\alpha$ & alpha \pronounced{AL-fuh} & $\nu$ & nu \pronounced{NEW} \\
% 		$\beta$ & beta \pronounced{BAY-tuh} & $\xi$, $\Xi$ & xi \pronounced{KSIGH} \\ 
% 		$\gamma$, $\Gamma$ & gamma \pronounced{GAM-muh} & o & omicron \pronounced{OM-uh-CRON} \\
% 		$\delta$, $\Delta$ & delta \pronounced{DEL-tuh} & $\pi$, $\Pi$ & pi \pronounced{PIE} \\
% 		$\epsilon$ & epsilon \pronounced{EP-suh-lon} & $\rho$ & rho \pronounced{ROW} \\
% 		$\zeta$ & zeta \pronounced{ZAY-tuh} & $\sigma$, $\Sigma$ & sigma \pronounced{SIG-muh} \\
% 		$\eta$ & eta \pronounced{AY-tuh} & $\tau$ & tau \pronounced{TOW (as in cow)} \\
% 		$\theta$, $\Theta$ & theta \pronounced{THAY-tuh} & $\upsilon$, $\Upsilon$ & upsilon \pronounced{OOP-suh-LON} \\
% 		$\iota$ & iota \pronounced{eye-OH-tuh} & $\phi$, $\Phi$ & phi \pronounced{FEE, or FI (as in hi)} \\
% 		$\kappa$ & kappa \pronounced{KAP-uh} & $\chi$ & chi \pronounced{KI (as in hi)} \\
% 		$\lambda$, $\Lambda$ & lambda \pronounced{LAM-duh} & $\psi$, $\Psi$ & psi \pronounced{SIGH, or PSIGH} \\
% 		$\mu$ & mu \pronounced{MEW} & $\omega$, $\Omega$ & omega \pronounced{oh-MAY-guh} \\
% 		\bottomrule
% 	\end{tabular} \\[1.5ex]
% 	Capitals shown are the ones that differ from Roman capitals.
% \end{center}

%----------------------------------------------------------------------------------------
%	GLOSSARY
%----------------------------------------------------------------------------------------

% The glossary needs to be compiled on the command line with 'makeglossaries main' from the template directory

% \newglossaryentry{computer}{
% 	name=computer,
% 	description={is a programmable machine that receives input, stores and manipulates data, and provides output in a useful format}
% }

% Glossary entries (used in text with e.g. \acrfull{fpsLabel} or \acrshort{fpsLabel})
% \newacronym[longplural={Frames per Second}]{fpsLabel}{FPS}{Frame per Second}
% \newacronym[longplural={Tables of Contents}]{tocLabel}{TOC}{Table of Contents}

% \setglossarystyle{listgroup} % Set the style of the glossary (see https://en.wikibooks.org/wiki/LaTeX/Glossary for a reference)
% \printglossary[title=Special Terms, toctitle=List of Terms] % Output the glossary, 'title' is the chapter heading for the glossary, toctitle is the table of contents heading

%----------------------------------------------------------------------------------------
%	INDEX
%----------------------------------------------------------------------------------------

% The index needs to be compiled on the command line with 'makeindex main' from the template directory

% \printindex % Output the index

%----------------------------------------------------------------------------------------
%	BACK COVER
%----------------------------------------------------------------------------------------

% If you have a PDF/image file that you want to use as a back cover, uncomment the following lines

%\clearpage


\end{document}


